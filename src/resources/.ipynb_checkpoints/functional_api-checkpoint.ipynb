{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
    "from sklearn.metrics import roc_curve, auc,  precision_score, recall_score, accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import PIL\n",
    "from PIL import ImageFile, Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_time = pd.read_csv('../data/notime_df.csv')\n",
    "no_time = no_time.loc[:, ~no_time.columns.str.contains('^Unnamed')]\n",
    "no_time = no_time.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fire(object):\n",
    "    def __init__(self, df):\n",
    "        self.y = df.pop('Target')\n",
    "        self.X = df\n",
    "\n",
    "    def split(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2, stratify=self.y)\n",
    "\n",
    "    def fit(self, model):\n",
    "        self.model = model\n",
    "        kf = KFold(n_splits=5)\n",
    "        \n",
    "        accuracy = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        f1 = []\n",
    "\n",
    "        for train_index, test_index in kf.split(self.X_train):\n",
    "            X_train_split, X_test_split = self.X_train.iloc[train_index], self.X_train.iloc[test_index]\n",
    "            y_train_split, y_test_split = self.y_train.iloc[train_index], self.y_train.iloc[test_index]\n",
    "            self.model.fit(X_train_split, y_train_split, verbose=True)\n",
    "            self.pred = self.model.predict(X_test_split)\n",
    "\n",
    "            assess = lambda method, val=y_test_split, pred=self.pred: method(val, pred)\n",
    "\n",
    "            accuracy.append(assess(accuracy_score))\n",
    "            precision.append(assess(precision_score))\n",
    "            recall.append(assess(recall_score))\n",
    "            f1.append(assess(f1_score))\n",
    "        \n",
    "        return np.mean(accuracy), np.mean(precision), np.mean(recall), np.mean(f1)\n",
    "    \n",
    "    def predict(self, df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 10,\n",
    "          'colsample_bytree': 0.4,\n",
    "          'subsample': 0.8,\n",
    "          'min_child_weight': 6,\n",
    "          'n_estimators': 1000, \n",
    "          'learning_rate': 0.01,\n",
    "          'lambda': 0.8,\n",
    "          'alpha': 0.5}\n",
    "boost = XGBClassifier()\n",
    "boost = XGBClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9740829311521617,\n",
       " 0.9021707949129162,\n",
       " 0.31995659247723135,\n",
       " 0.47228727445462093)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_boost = Fire(no_time)\n",
    "data_boost.split()\n",
    "data_boost.predict(boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "norcal = pd.read_csv('../data/norcal.csv')\n",
    "norcal = norcal.loc[:, ~norcal.columns.str.contains('^Unnamed')]\n",
    "socal = pd.read_csv('../data/socal.csv')\n",
    "socal = socal.loc[:, ~socal.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input a date and select a region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinedModels():\n",
    "    region = input('Enter \"norcal\" or \"socal\":  ')\n",
    "    date = input('Enter a date between 1/1/2018 and 9/13/2020:  ')\n",
    "    \n",
    "    xception = load_model('xception_50epoch.h5')\n",
    "    batch_size = 16\n",
    "    img_height = 256\n",
    "    img_width = 256\n",
    "    epochs=50\n",
    "    \n",
    "    if region == 'norcal':\n",
    "        norcal = pd.read_csv('../data/norcal.csv')\n",
    "        norcal = norcal.loc[:, ~norcal.columns.str.contains('^Unnamed')]\n",
    "        df = norcal[norcal['Date']==date]\n",
    "        df.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "        # reformat date: 9/1/2020 -> 2020-09-01\n",
    "        datetime = pd.to_datetime(date, format='%m/%d/%Y')\n",
    "        datetime = datetime.strftime('%Y-%m-%d')\n",
    "        # find it in cleaned_data image files\n",
    "        path = glob.glob(f'../data/cleaned_data/*/{datetime}_1.jpg')\n",
    "        path = ''.join(element for element in path)\n",
    "        image = tf.keras.preprocessing.image.load_img(path, interpolation=\"bilinear\")\n",
    "        input_arr = keras.preprocessing.image.img_to_array(image)\n",
    "        input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "        image_risk = xception.predict(input_arr,batch_size=batch_size)\n",
    "        \n",
    "    elif region == 'socal':\n",
    "        socal = pd.read_csv('../data/socal.csv')\n",
    "        socal = socal.loc[:, ~socal.columns.str.contains('^Unnamed')]\n",
    "        df = socal[socal['Date']==date]\n",
    "        df.drop('Date', axis=1, inplace=True)\n",
    "        \n",
    "        # reformat date: 9/1/2020 -> 2020-09-01\n",
    "        datetime = pd.to_datetime(date, format='%m/%d/%Y')\n",
    "        datetime = datetime.strftime('%Y-%m-%d')\n",
    "        # find it in cleaned_data image files\n",
    "        path = glob.glob(f'../data/cleaned_data/*/{datetime}.jpg')\n",
    "        path = ''.join(element for element in path)\n",
    "        image = tf.keras.preprocessing.image.load_img(path, interpolation=\"bilinear\")\n",
    "        input_arr = keras.preprocessing.image.img_to_array(image)\n",
    "        input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "        image_risk = xception.predict(input_arr,batch_size=batch_size)\n",
    "        \n",
    "    conditions_y = df.pop('Target')\n",
    "    conditions_y_pred = boost.predict(df)\n",
    "    conditions_risk = np.mean(conditions_y_pred)\n",
    "    \n",
    "    risk = .8*(image_risk.ravel()[0]) + 0.2*conditions_risk\n",
    "\n",
    "    return print(f'Risk for fire in {region} on {date} was: {round(risk,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter \"norcal\" or \"socal\":  norcal\n",
      "Enter a date between 1/1/2018 and 9/13/2020:  8/5/2020\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_1_8:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2276, 2276, 3).\n",
      "WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8aea54eca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Risk for fire in norcal on 8/5/2020 was: 0.81\n"
     ]
    }
   ],
   "source": [
    "combinedModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception = load_model('xception_50epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs: image and conditions\n",
    "# include date prior to both these inputs to specify\n",
    "# norcal or socal and where in conditions df to look\n",
    "\n",
    "date_input = keras.Input(input('Enter a date between 1/1/2018 and 9/13/2020:  '))\n",
    "region_input = keras.Input(input('Enter \"norcal\" or \"socal\":  '))\n",
    "\n",
    "image_input = keras.Input(\n",
    "    shape=(img_height, img_width, 3), \n",
    "    name=\"satellite_image\"\n",
    "    ) \n",
    "\n",
    "conditions_input = keras.Input(\n",
    "    shape=(None,), \n",
    "    name=\"conditions\")\n",
    "\n",
    "\n",
    "xception_model=load_model('xception_50epoch.h5')(image_input)\n",
    "xception = layers.xception_model()(image_input)\n",
    "\n",
    "probability1 = xception\n",
    "probability2 = \n",
    "\n",
    "fire_risk = layers.average(x)\n",
    "\n",
    "bigmodel = keras.Model(\n",
    "    inputs = [image_input, conditions_input, date_input]\n",
    "    outputs = fire_risk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
